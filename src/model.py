import google.generativeai as genai
import os

import streamlit as st

from typing import List

from prompt import PromptTemplate

import json

api_key = os.environ["API_KEY"] if "API_KEY" in os.environ else st.secrets["API_KEY"]
api_key1 = os.environ["API_KEY"] if "API_KEY1" in os.environ else st.secrets["API_KEY1"]
api_key2 = os.environ["API_KEY"] if "API_KEY2" in os.environ else st.secrets["API_KEY2"]
api_key3 = os.environ["API_KEY"] if "API_KEY3" in os.environ else st.secrets["API_KEY3"]

pt = PromptTemplate()

def get_models() -> List:

    """
    Retrieve available Google Gemnini models that support content generation.

    Returns:
        list: A list of model names that support content generation.

    """
    genai.configure(api_key=api_key3)
    models = [model.name for model in genai.list_models() if 'generateContent' in model.supported_generation_methods]
    models = [model[7:] for model in models]
    return models
    

class Model():
    def __init__(self, operation : str, model : str, api_key : str):

        """
        Initialize a Model instance for generating content using GenAI.

        Args:
            operation (str): The type of operation ('search', 'answer', or 'related_queries').
            model (str): The name of the model to be used for generation.
            api_key (str): The API key for authenticating with GenAI.

        Attributes:
            response_type (str or None): The MIME type for the response based on the operation type.
            system_instruction (str or None): The system instruction for the model based on the operation type.
            model (GenerativeModel): The configured GenAI generative model instance.
        """

        self.model = model

        self.response_type = "application/json" if operation in ['related_queries', 'search'] else None

        self.system_instruction = (
            pt.answer_systeminstruction() if operation == 'answer' 
            else None if operation == 'search' 
            else None
        )

        genai.configure(api_key=api_key)
        generation_config = genai.types.GenerationConfig(
            max_output_tokens=2500,
            temperature=1.0, response_mime_type=self.response_type
        )
        self.model = genai.GenerativeModel(
            self.model,
            generation_config=generation_config,
            safety_settings=[
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_NONE",
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_NONE",
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_NONE",
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_NONE",
                },
            ],
            system_instruction=self.system_instruction
        )
        
    def search(self, query : str, history : List, enable_history : bool = True) -> List:
        """

        Generate a search response based on the given query and history.

        Args:
            query (str): The search query to be processed.
            history (list): Previous queries or context history for the search.
            enable_history (bool): Flag indicating whether to use history in the search.

        Returns:
            list: The search results generated by the model.

        """
        messages = [{'role': 'user', 'parts': [pt.search_systeminstruction(query=query, history=history, enable_history=enable_history)]}]
        response = self.model.generate_content(messages)
        response = json.loads(response.text)
        return response[:1]
    

    def answer(self, query : str, context : str):
        """

        Generate an answer to the given query based on the provided context.

        Args:
            query (str): The question to be answered.
            context (str): The context or information to assist in answering the question.

        Yields:
            str: The generated answer tokens one by one.

        """
        messages = [
            {
                'role': 'user',
                'parts': [pt.prompttemplate(query, context)]
            }
        ]
        for response in self.model.generate_content(messages, stream=True):
            for token in response:
                yield token.text
    
    def related_queries(self, query : str, answer : str) -> List[str]:
        """

        Generate related queries based on the provided query and its answer.

        Args:
            query (str): The original query.
            answer (str): The answer corresponding to the original query.

        Returns:
            list: A list of queries related to the original query and answer.

        """
        
        messages = [
            {
                'role': 'user',
                'parts': [pt.related_queries(query=query, answer=answer)]
            }
        ]
        response = self.model.generate_content(messages)
        response = json.loads(response.text)
        return response
    

#if __name__ == "__main__":
#    model = Model(operation='search', model="gemini-1.5-flash", api_key=api_key1)
#    search_query = model.search(query="What are different types of medical devices regulations in India and USA", history='', enable_history=False)
